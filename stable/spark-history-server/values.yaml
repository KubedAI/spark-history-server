# Default values for spark-history-server.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: ghcr.io/kubedai/spark-history-server
  pullPolicy: Always
  # Overrides the image tag whose default is the chart appVersion.
  tag: aws-latest # or "azure-latest" or your specific version

  # To pull images from the registries like ghcr.io, you need to authenticate and provide the imagePullSecrets as described here:
  # https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  # If you have already created a secret for pulling images from ghcr.io, you can specify it in property imagePullSecrets.
  # If you don't have a secret yet, you can create one using the property pullCredentials.

  # See the pullSecrets field within the container definitions of a Pod: https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#containers
  pullSecrets: [ ]

  # If you want the Helm chart to take care of the secret creation, generate a personal access token as described here:
  # https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry#authenticating-to-the-container-registry
  pullCredentials:
    enabled: false
    secretName: ghcr-io-pull-secret
    registry: ghcr.io
    username: <GITHUB USERNAME>
    password: <GITHUB PERSONAL ACCESS TOKEN>
    email: <GITHUB EMAIL>

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  name: spark-history-server-sa
  annotations: { }

logStore:
  # Enter the type of log store to use. Supported values are "s3", "abfs", and "local".
  # Remember
  type: "s3"  # or "abfs" or "local" depending on which storage you're targeting

  s3:
    # Ensure IRSA roles has permissions to read the files for the given S3 bucket
    bucket: "example-bucket"  # This is just a placeholder for publishing
    eventLogsPath: "spark-events/"  # This is just a placeholder for publishing
    irsaRoleArn: "arn:aws:iam::123456789012:role/example-role"  # This is just a placeholder for publishing

  abfs:
    container: <ABFS CONTAINER NAME>
    storageAccount: <STORAGE ACCOUNT NAME>
    clientId: <CLIENT ID>
    clientSecret: <CLIENT SECRET>
    tenantId: <TENANT ID>
    eventLogsPath: <PREFIX FOR SPARK EVENT LOGS>
    
  local:
    directory: "/home"

# Extra configuration for spark-defaults.conf - Storage backend optimizations only
sparkConf: |-
  # Storage backend optimizations for S3/ABFS (non-conflicting settings)
  spark.hadoop.fs.s3a.connection.maximum=200
  spark.hadoop.fs.s3a.threads.max=50
  spark.hadoop.fs.s3a.max.total.tasks=100
  spark.hadoop.fs.s3a.connection.establish.timeout=10000
  spark.hadoop.fs.s3a.connection.timeout=20000

log4jConfig: |-
  rootLogger.level = info
  rootLogger.appenderRef.stdout.ref = console
  appender.console.type = Console
  appender.console.name = console
  appender.console.target = SYSTEM_ERR
  appender.console.layout.type = PatternLayout
  appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n%ex

  logger.spark.name = org.apache.spark
  logger.spark.level = INFO
  logger.hadoop.name = org.apache.hadoop
  logger.hadoop.level = INFO
  logger.s3a.name = org.apache.hadoop.fs.s3a
  logger.s3a.level = INFO
  logger.history.name = org.apache.spark.deploy.history.FsHistoryProvider
  logger.history.level = INFO

persistence: # enabled if historyServer.store.hybridStore.enabled is true
  enabled: false
  mountPath: "/mnt/shs-cache"
  storageClass: ""
  size: "10Gi"

historyServer:
  store: # corresponds to spark.history.store.* settings
    path: "/mnt/shs-cache"
    maxDiskUsage: 9g
    hybridStore:
      enabled: false
      maxMemoryUsage: 2g
      diskBackend: ROCKSDB
      serializer: PROTOBUF
  fs:
    update:
      interval: 10s
    cleaner:
      enabled: false
      interval: 1d
      maxAge: 7d
      maxNum: 2147483647 #Int.MaxValue
    endEventReparseChunkSize: 1m
    # Issue #46: Increase replay threads from default 25% to fixed 4 threads
    numReplayThreads: 4
    inProgressOptimization:
      enabled: true
    driverlog:
      cleaner:
        enabled: false
        interval: 1d
        maxAge: 7d
    eventLog:
      rolling:
        maxFilesToRetain: 2147483647 # Int.MaxValue
  retainedApplications: 100  # Increased from 50 for better performance
  ui:
    maxApplications: 2147483647 # Int.MaxValue


podAnnotations: { }

# Extra custom labels for pods
podLabels: { }

# Environment variables - Addressing GitHub issue #47 (SPARK_DAEMON_MEMORY)
env:
  - name: SPARK_DAEMON_MEMORY
    value: "4g"  # Increased from default 2g for better performance
  - name: SPARK_DAEMON_JAVA_OPTS
    value: >-
      -XX:+UseG1GC
      -XX:MaxGCPauseMillis=200
      -XX:G1HeapRegionSize=32m
      -XX:+UseStringDeduplication
      -XX:+UseCompressedOops
      -XX:+UseCompressedClassPointers

podSecurityContext:
  runAsUser: 1000
  fsGroup: 1000

securityContext:
  capabilities:
    drop:
      - ALL
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 1000

service:
  externalPort: 80
  internalPort: 18080
  type: ClusterIP

ingress:
  enabled: false
  annotations: { }
  ingressClassName: <INGRESS CLASS NAME>
  hosts:
    - host: <YOUR HOST NAME>
      paths:
        - path: "^/$"
#         pathType: ImplementationSpecific

resources:
  limits:
    # cpu: removed per GitHub issue #41 - allow CPU bursting
    memory: 6Gi  # Increased from 2G per GitHub issue #47
  requests:
    cpu: 500m     # Increased from 100m for better minimum allocation
    memory: 4Gi   # Increased from 1G to support larger SPARK_DAEMON_MEMORY

livenessProbe:
  httpGet:
    path: /
    port: 18080
    scheme: HTTP
  initialDelaySeconds: 60  # SHS startup can be slow with optimized memory
  timeoutSeconds: 10       # Increased from 5 for better reliability
  periodSeconds: 30
  successThreshold: 1
  failureThreshold: 5      # More tolerant of temporary failures

readinessProbe:
  httpGet:
    path: /
    port: 18080
    scheme: HTTP
  initialDelaySeconds: 30  # Allow time for SHS initialization
  timeoutSeconds: 10       # Increased from 5
  periodSeconds: 15        # More frequent checks for faster recovery
  successThreshold: 1
  failureThreshold: 3

nodeSelector: { }

tolerations: [ ]

affinity: { }
